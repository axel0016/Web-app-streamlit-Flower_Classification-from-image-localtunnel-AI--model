{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b71zzyz-KQnO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzZ-B5EfLLPg"
      },
      "outputs": [],
      "source": [
        "!pip install layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sinWm7T2M3UG",
        "outputId": "894c96b6-eef8-48f3-b0e8-b1b3618ad294"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Sequential\n",
            "  Downloading sequential-1.0.0.tar.gz (2.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Sequential\n",
            "  Building wheel for Sequential (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Sequential: filename=sequential-1.0.0-py3-none-any.whl size=2879 sha256=131f56e54929151e35059644a20f4858c4d129329e91ebb9e53428f6d8fb89d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/3c/18/25bc0c5ef268ffb0e7ec631e2dde620b8c688586e9bb0bfa52\n",
            "Successfully built Sequential\n",
            "Installing collected packages: Sequential\n",
            "Successfully installed Sequential-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install Sequential\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM7YgBEAM80m"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-TAg8fsQhVd"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTB314jRQk5E"
      },
      "outputs": [],
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "print(roses[0])\n",
        "PIL.Image.open(str(roses[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4O-D5oQZeEG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVjIaXSAQrsn"
      },
      "outputs": [],
      "source": [
        "img_height,img_width=180,180\n",
        "batch_size=32\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfOqRAmOQ8fN"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOPLGaw7RUKY"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "from joblib import dump,load\n",
        "dump(class_names,'class.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73hGx5S5RNnE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2SAkvPwRR8c"
      },
      "outputs": [],
      "source": [
        "num_classes = 5\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes,activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4GzF7LIRklw"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERjEIVnfRnw6"
      },
      "outputs": [],
      "source": [
        "epochs=6\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTpUWUsURp4o"
      },
      "outputs": [],
      "source": [
        "tf.keras.models.save_model(model,'my_model2.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSd9-lx1XZBL"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hITsMcELVgQA"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import streamlit as st\n",
        "from joblib import dump,load\n",
        "class_names=load('class.joblib')\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def load_model():\n",
        "  model=tf.keras.models.load_model('/content/my_model2.hdf5')\n",
        "  return model\n",
        "with st.spinner('Model is being loaded..'):\n",
        "  model=load_model()\n",
        "\n",
        "st.write(\"\"\"\n",
        "         # Flower Classification\n",
        "         \"\"\"\n",
        "         )\n",
        "\n",
        "file = st.file_uploader(\"Please upload an brain scan file\", type=[\"jpg\", \"png\"])\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "def import_and_predict(image_data, model):\n",
        "    \n",
        "        size = (180,180)    \n",
        "        image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n",
        "        image = np.asarray(image)\n",
        "        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        #img_resize = (cv2.resize(img, dsize=(75, 75),    interpolation=cv2.INTER_CUBIC))/255.\n",
        "        \n",
        "        img_reshape = img[np.newaxis,...]\n",
        "    \n",
        "        prediction = model.predict(img_reshape)\n",
        "        \n",
        "        return prediction\n",
        "if file is None:\n",
        "    st.text(\"Please upload an image file\")\n",
        "else:\n",
        "    image = Image.open(file)\n",
        "    st.image(image, use_column_width=True)\n",
        "    prediction = import_and_predict(image, model)\n",
        "    score = tf.nn.softmax(prediction[0])\n",
        "    st.write(prediction)\n",
        "    st.write(score)\n",
        "    st.write(\"----------------------------------\")\n",
        "    st.write(class_names)\n",
        "    st.write(class_names[np.argmax(score)])\n",
        "    print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jn9jkmLYoo1"
      },
      "outputs": [],
      "source": [
        "from joblib import dump,load\n",
        "class_names=load('class.joblib')\n",
        "score = tf.nn.softmax([0.15381634,0.15400618 ,0.3638333, 0.15353513 ,0.17480898])\n",
        "class_names[np.argmax(score)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGeOWyFiZQym"
      },
      "outputs": [],
      "source": [
        "!streamlit run /content/app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}